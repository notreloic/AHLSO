# AHLSO
## Information 
This repository includes the code for the algorithm of "An Agent-assisted Heterogeneous Learning Swarm Optimizer for Large-Scale Optimization (AHLSO)" which is published on journal of Swarm and Evolutionary Computation. 

## Run
You can run the RUM_DEMO.m to run AHLSO on CEC 2010/2013 large scale optimization benchmarks.

## Copyright and Citation 
If you further study based on this want to do project, please cite this paper as "Sun Y, Han C, An agent-assisted heterogeneous learning swarm optimizer for large-scale optimization ［3］. Swarm and Evolutionary Computation, 2024, 89: 101627."And the bibTex "@article{SUN2024101627,
title = {An agent-assisted heterogeneous learning swarm optimizer for large-scale optimization},
journal = {Swarm and Evolutionary Computation},
volume = {89},
pages = {101627},
year = {2024},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2024.101627},
url = {https://www.sciencedirect.com/science/article/pii/S2210650224001652},
author = {Yu Sun and Han Cao},
keywords = {Heterogeneous learning, Reinforcement learning (Agent), Resource allocation, Swarm optimizer, Large-scale optimization problems},
abstract = {In large-scale optimization problems, the PSO algorithm based on population information interaction performs well. However, the algorithm typically only uses population information for updating, neglecting potentially useful information during evolution. Furthermore, the pressure of computing resources and complex evolution processes pose challenges to search and balancing strategy. In this paper, an agent-assisted heterogeneous learning swarm optimizer is proposed. First, a global and local search collaborative particle learning structure is proposed, called a heterogeneous learning structure. The population distribution in the decision and objective spaces are used to select global and local search examples, respectively. Secondly, an agent-assisted evolutionary search is proposed, which evaluates the individual’s state in decision space and objective space and controls the global and local search structures to adapt to the evolutionary requirements of individuals in different evolutionary states. Finally, hierarchical resource allocation and level-based global search example selection mechanisms are proposed on the local and global search structures to maintain the balance between diversity and convergence. To evaluate the performance of the proposed algorithm, comprehensive and extensive experiments were conducted on a commonly used large-scale benchmark suite. Experiments show that compared with ten state-of-the-art large-scale optimization algorithms, the proposed algorithm demonstrates superior performance in most cases.}
}
## Paper link

## Author contact information
Email: caohan_cs@163.com
